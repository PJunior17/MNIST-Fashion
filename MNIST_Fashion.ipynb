{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPrgiwlnnt3yoRMq5z5x/5g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "55c87a7c540b4055b4e987ac366f8692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_165e4a67f47040108bd7b510bfd539e1",
              "IPY_MODEL_b96cdf3d15ac4516bffdee3f23fd6f54",
              "IPY_MODEL_2aba8dfe4d834cc4b5081830ea2043d5"
            ],
            "layout": "IPY_MODEL_9e183da2685f4b4080b997c3509581fc"
          }
        },
        "165e4a67f47040108bd7b510bfd539e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_852afc9cf4b04fdebcdac4fc4b39ee39",
            "placeholder": "​",
            "style": "IPY_MODEL_f40180d4ce584815815751e1efe78fc2",
            "value": "100%"
          }
        },
        "b96cdf3d15ac4516bffdee3f23fd6f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab8df6035446489ba143b5f07d18a3f3",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9532afe308dc46d2930f19537570c73a",
            "value": 3
          }
        },
        "2aba8dfe4d834cc4b5081830ea2043d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88e762f3d0e346199db7c8d6c3755ed5",
            "placeholder": "​",
            "style": "IPY_MODEL_3aa76435fa9548ac8663dd25efdcfbcc",
            "value": " 3/3 [00:41&lt;00:00, 13.86s/it]"
          }
        },
        "9e183da2685f4b4080b997c3509581fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "852afc9cf4b04fdebcdac4fc4b39ee39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f40180d4ce584815815751e1efe78fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab8df6035446489ba143b5f07d18a3f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9532afe308dc46d2930f19537570c73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88e762f3d0e346199db7c8d6c3755ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa76435fa9548ac8663dd25efdcfbcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PJunior17/MNIST-Fashion/blob/main/MNIST_Fashion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v9eWOzjIXRP",
        "outputId": "b74cb51a-c982-468a-96e8-6497733dece9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.1 torchmetrics-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyXUEdfftFGU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import torchmetrics\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare and Load Data"
      ],
      "metadata": {
        "id": "6mbjKVVNtYy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(root='data',\n",
        "                                   train=True,\n",
        "                                   download=True,\n",
        "                                   transform=ToTensor(),\n",
        "                                   target_transform=None)\n",
        "\n",
        "test_data = datasets.FashionMNIST(root='data',\n",
        "                                  train=False,\n",
        "                                  download=True,\n",
        "                                  transform=ToTensor())\n",
        "\n",
        "image, label = train_data[0]"
      ],
      "metadata": {
        "id": "5Q04lRHiteh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "#this will turn the dataset into an iterable (batches)\n",
        "train_dataloader = DataLoader(train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)"
      ],
      "metadata": {
        "id": "hZBcE5CquAnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "_pMF_fO_w65a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Model"
      ],
      "metadata": {
        "id": "cK3--XaUxfNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_model = nn.Flatten()\n",
        "x = train_features_batch[0]\n",
        "output = flatten_model(x)"
      ],
      "metadata": {
        "id": "SYDYFUicyLOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and Test functions"
      ],
      "metadata": {
        "id": "F-nYPvUeyXOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model:torch.nn.Module,\n",
        "               data_loader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               optimizer:torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device:torch.device = device):\n",
        "  train_loss, train_acc = 0, 0\n",
        "  model.to(device)\n",
        "  for batch, (X, y) in enumerate(data_loader):\n",
        "    X, y = X.to(device), y.to(device) #send data to GPU\n",
        "    y_pred = model(X) #forward propagation\n",
        "    loss = loss_fn(y_pred, y) #calculate the loss\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_pred, y)\n",
        "    optimizer.zero_grad() #optimizer zero grad\n",
        "    loss.backward() #backward propagation\n",
        "    optimizer.step() #optimizer step\n",
        "\n",
        "  #calculate the loss and accuracy per epoch, which is why we divide by the len(data_loader)\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "  print('Train Loss: %s | Train Accuracy: %s' % (train_loss, train_acc))\n",
        "\n",
        "def test_step(model:torch.nn.Module,\n",
        "              data_loader:torch.utils.data.DataLoader,\n",
        "              loss_fn:torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device:torch.device = device):\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model.to(device)\n",
        "  model.eval() #put the mode to eval mode\n",
        "\n",
        "  #turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "    for X, y in data_loader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      test_pred = model(X) #forward propagation\n",
        "      test_loss += loss_fn(test_pred, y)\n",
        "      test_acc += accuracy_fn(test_pred, y)\n",
        "    test_loss /= len(data_loader)\n",
        "    test_acc /= len(data_loader)\n",
        "    print('Test Loss: %s | Test Accuracy: %s' % (test_loss, test_acc))\n"
      ],
      "metadata": {
        "id": "ztEZzzoVzfnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://poloclub.github.io/cnn-explainer/\n",
        "use this link to understand more about convolutional neural networks"
      ],
      "metadata": {
        "id": "ZQEBqeCV3rsw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolutional Neural Network"
      ],
      "metadata": {
        "id": "uDXWsctG4F26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape:int,\n",
        "               hidden_units:int,\n",
        "               output_shape:int):\n",
        "    super(Model, self).__init__()\n",
        "    self.block1 = nn.Sequential(nn.Conv2d(in_channels=input_shape,\n",
        "                                          out_channels=hidden_units,\n",
        "                                          kernel_size=3,\n",
        "                                          stride=1,\n",
        "                                          padding=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Conv2d(in_channels=hidden_units,\n",
        "                                          out_channels=hidden_units,\n",
        "                                          kernel_size=3,\n",
        "                                          stride=1,\n",
        "                                          padding=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.MaxPool2d(kernel_size=2,\n",
        "                                             stride=2))\n",
        "    self.block2 = nn.Sequential(nn.Conv2d(in_channels=hidden_units,\n",
        "                                          out_channels=hidden_units,\n",
        "                                          kernel_size=3,\n",
        "                                          stride=1,\n",
        "                                          padding=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Conv2d(in_channels=hidden_units,\n",
        "                                          out_channels=hidden_units,\n",
        "                                          kernel_size=3,\n",
        "                                          stride=1,\n",
        "                                          padding=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.MaxPool2d(kernel_size=2,\n",
        "                                             stride=2))\n",
        "    self.classifier = nn.Sequential(nn.Flatten(),\n",
        "                                    nn.Linear(in_features=hidden_units*7*7,\n",
        "                                              out_features=output_shape))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block1(x)\n",
        "    #print('First Sequence Shape: %s' % str(x.shape))\n",
        "    x = self.block2(x)\n",
        "    #print('Second Sequence Shape: %s' % str(x.shape))\n",
        "    x = self.classifier(x)\n",
        "    #print('Third Sequence Shape: %s' % str(x.shape))\n",
        "    return x\n",
        "\n",
        "torch.manual_seed(17)\n",
        "class_names = train_data.classes\n",
        "model = Model(input_shape=1, hidden_units=10, output_shape=len(class_names)).to(device)\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "_LvChsHx4PoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9366eb3-9e9e-4011-f36a-baa6f92d37fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (block1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stepping throuh nn.Conv2d()"
      ],
      "metadata": {
        "id": "5EgvI5_2opnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Conv2d() is known as the convolutional layer\n",
        "\n",
        "nn.MaxPool2d() is known as the pooling layer"
      ],
      "metadata": {
        "id": "vxULhk5owsDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(17)\n",
        "\n",
        "#lets create a test batch and test image and see convolution in action\n",
        "images = torch.randn(size=(32, 3, 64, 64)) #batch size, color channel, height, width\n",
        "test_image = images[0]\n",
        "images.shape, test_image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx1FAnJHxI6h",
        "outputId": "48b1c82d-9c4e-42bb-9b80-d3e11f2fcef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3, 64, 64]), torch.Size([3, 64, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(17)\n",
        "conv_layer = nn.Conv2d(in_channels=3,\n",
        "                       out_channels=10,\n",
        "                       kernel_size=3,\n",
        "                       stride=1,\n",
        "                       padding=0)\n",
        "conv_layer(test_image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wO6RAgvzM5P",
        "outputId": "6d82c592-944a-4a9f-cd10-0ea819a7bba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.2188,  0.1430, -0.1163,  ...,  0.5358,  0.5758,  0.6098],\n",
              "         [-0.3033, -0.2936,  0.3397,  ...,  0.1682,  0.4830,  0.2618],\n",
              "         [-0.2086, -0.9499, -0.1853,  ..., -0.3184,  0.2549, -0.6586],\n",
              "         ...,\n",
              "         [-0.3269,  0.2665,  0.0794,  ..., -1.3813, -1.3286, -0.6917],\n",
              "         [-0.1882,  0.1220, -0.1316,  ..., -0.8738, -1.0345, -0.9743],\n",
              "         [-0.5635, -0.0239, -0.6342,  ..., -0.3326,  0.2546,  0.5386]],\n",
              "\n",
              "        [[-0.4617, -0.9907, -0.6248,  ..., -0.2021, -0.7061,  0.3379],\n",
              "         [-0.0382, -0.3555, -0.0692,  ..., -0.6126,  0.2066,  0.3084],\n",
              "         [ 0.7285,  0.1415,  0.5137,  ..., -1.3283, -0.5452,  0.1768],\n",
              "         ...,\n",
              "         [ 0.5590,  0.2779,  0.0404,  ..., -0.5979,  0.6375, -0.0293],\n",
              "         [-0.6820,  0.5112,  0.4071,  ..., -0.2713, -1.0799, -0.1871],\n",
              "         [ 0.1917, -0.1398, -0.3813,  ...,  0.1202,  0.1425, -0.8015]],\n",
              "\n",
              "        [[ 0.9488, -0.1764, -0.2073,  ..., -0.2424,  0.8406,  0.3455],\n",
              "         [ 0.1788, -0.0309, -0.6543,  ...,  0.2706,  1.7441,  0.6137],\n",
              "         [ 0.3167, -0.3294,  0.7291,  ..., -0.1021, -1.2331,  0.0926],\n",
              "         ...,\n",
              "         [ 0.5129, -0.0819,  0.8407,  ...,  0.3642,  0.1349,  0.4815],\n",
              "         [ 0.0659,  0.1078,  0.4859,  ..., -0.5938, -0.3518, -1.3686],\n",
              "         [ 0.3843, -0.2290,  0.7478,  ..., -0.8097,  0.0208, -0.5083]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.5894,  0.3566,  0.3901,  ...,  0.8786, -0.3079,  0.1623],\n",
              "         [ 0.7747,  0.3889,  0.5388,  ...,  0.0269,  0.2331, -0.1600],\n",
              "         [ 0.4049,  0.9891, -0.2025,  ...,  0.5461, -0.2473, -0.3049],\n",
              "         ...,\n",
              "         [ 0.2860,  0.3059, -0.4550,  ...,  0.7289,  0.1973,  0.4585],\n",
              "         [-0.6345, -0.0560,  0.5288,  ...,  1.9183, -0.0610,  0.6637],\n",
              "         [ 0.0674, -0.1604,  0.1889,  ...,  0.2070,  1.0111,  0.3920]],\n",
              "\n",
              "        [[ 0.4620,  0.6510,  0.4269,  ...,  1.3158,  0.0922, -0.1410],\n",
              "         [-0.6831,  0.7534,  0.2299,  ...,  1.0225,  0.3955,  0.2269],\n",
              "         [ 0.1982,  0.0885,  0.4097,  ...,  0.0876, -0.0245,  0.1290],\n",
              "         ...,\n",
              "         [ 0.0047,  0.1679,  0.1205,  ..., -0.3507,  0.0350,  1.1136],\n",
              "         [-0.5693, -0.7813,  0.1633,  ...,  0.2078,  0.3054,  0.2889],\n",
              "         [-0.4846, -0.1739,  0.6999,  ...,  0.6606,  0.7734,  1.1782]],\n",
              "\n",
              "        [[-0.1708, -0.3815, -1.0988,  ..., -0.7364, -0.0881, -0.8301],\n",
              "         [ 0.5069, -0.1526, -0.4339,  ..., -0.1638,  0.0203, -0.7729],\n",
              "         [ 0.3442,  0.5562, -0.0706,  ...,  0.5200,  0.1971,  0.8540],\n",
              "         ...,\n",
              "         [-0.2546, -0.3937, -0.6248,  ...,  1.0004,  0.5290,  0.3571],\n",
              "         [ 0.7045, -0.6539,  1.6731,  ...,  0.0345, -0.2466,  0.0566],\n",
              "         [ 0.7425, -0.4701,  0.2021,  ..., -0.6825, -0.0095,  0.0822]]],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If on PyTorch 1.11.0 or below this would error out but we dont have to worry about that. Right now our test image only has 3 dimensions: color-channels, height, width. If we needed to fix this we can unsqueeze at dimension=0."
      ],
      "metadata": {
        "id": "EHhIvcxh0Ksu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image.unsqueeze(dim=0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLAAKTz81I0a",
        "outputId": "ef145831-9389-4f80-b827-0f97d895fb12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#notice the shape change\n",
        "conv_layer(test_image.unsqueeze(dim=0)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu9I0Hl022yD",
        "outputId": "077be2f9-a67c-45a6-97a2-2138b3828ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 62, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here lets change the convolutional layer kernel size to a 5x5 square instead of a 3x3 square\n",
        "conv_layer_2 = nn.Conv2d(in_channels=3,\n",
        "                         out_channels=10,\n",
        "                         kernel_size=(5,5),\n",
        "                         stride=2,\n",
        "                         padding=0)\n",
        "conv_layer_2(test_image.unsqueeze(dim=0)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75uzwkAG29cU",
        "outputId": "e0bd1d0d-71b7-4b58-885c-2858ba70d048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 30, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Behind the scenes, our nn.Conv2d() is compressing the information stored in the image.\n",
        "\n",
        "It does this by performing operations on the input (our test image) against its internal parameters.\n",
        "\n",
        "The goal of this is similar to all of the other neural networks we've been building.\n",
        "\n",
        "Data goes in and the layers try to update their internal parameters (patterns) to lower the loss function thanks to some help of the optimizer.\n",
        "\n",
        "The only difference is how the different layers calculate their parameter updates or in PyTorch terms, the operation present in the layer forward() method."
      ],
      "metadata": {
        "id": "rQneX-T_3zPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer_2.weight.shape, conv_layer_2.bias.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-EQw_Eb4FNc",
        "outputId": "9c71ee4c-efbd-4877-9221-e6a6058c729b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 3, 5, 5]), torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stepping through nn.MaxPool2d()"
      ],
      "metadata": {
        "id": "TUB-YRJg4ZFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Image original shape: %s' % str(test_image.shape))\n",
        "print('Test Image with unsqueezed dimension: %s' % str(test_image.unsqueeze(dim=0).shape))\n",
        "\n",
        "maxpool_layer = nn.MaxPool2d(kernel_size=2,\n",
        "                             stride=2) #the default value of stride is to match the kernel size but i like putting it for practice until i get it\n",
        "\n",
        "#passing data through the conv layer\n",
        "test_image_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
        "print('Shape after Conv Layer: %s' % str(test_image_conv.shape))\n",
        "\n",
        "#passing data though the pooling layer\n",
        "test_image_conv_pool = maxpool_layer(test_image_conv)\n",
        "print('Shape after Pooling Layer: %s' % str(test_image_conv_pool.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcdHDH2r4lxz",
        "outputId": "52ae44e3-934e-4f42-9479-df462026a7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Image original shape: torch.Size([3, 64, 64])\n",
            "Test Image with unsqueezed dimension: torch.Size([1, 3, 64, 64])\n",
            "Shape after Conv Layer: torch.Size([1, 10, 62, 62])\n",
            "Shape after Pooling Layer: torch.Size([1, 10, 31, 31])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With a kernel size of 2 and stride of 2 we can see that the pooling layer will halve the image. If we were to change the kernel size and stride then the number shape will change further too\n",
        "\n",
        "Essentially, every layer of a neural network is trying to compress data from a higher dimensional space to a lower dimensional space"
      ],
      "metadata": {
        "id": "45fh2lGZ6JYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "_aegNvlXDEpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will use CrossEntropyLoss as the loss function cuz we are doing multi-class classification\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=1e-1) #we are using SGD here but you can also use Adam\n",
        "                                                                #the difference is that you use SGD when you have a large dataset that is simpiler and you\n",
        "                                                                # want to compute quickly\n",
        "                                                                #use Adam when you have a large complex dataset and it will take longer to computer but\n",
        "                                                                # that's cuz Adam is more complex and does more things like auto tunes the learning rate\n",
        "\n"
      ],
      "metadata": {
        "id": "pOuVNEraEipE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model using the Train and Test Functions we made earlier"
      ],
      "metadata": {
        "id": "v-7FOooqGKVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float, end: float, device: torch.device = None):\n",
        "    \"\"\"Prints difference between start and end time.\n",
        "\n",
        "    Args:\n",
        "        start (float): Start time of computation (preferred in timeit format).\n",
        "        end (float): End time of computation.\n",
        "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        float: time between start and end in seconds (higher is longer).\n",
        "    \"\"\"\n",
        "    total_time = end - start\n",
        "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "    return total_time"
      ],
      "metadata": {
        "id": "8kKmDE0QJ9E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(17)\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "accuracy_fn = Accuracy(task='multiclass', num_classes=len(class_names)).to(device)\n",
        "\n",
        "train_time_start_time = timer()\n",
        "\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print('Epoch: %s \\n-----------' % (epoch))\n",
        "  train_step(model=model,\n",
        "             data_loader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device)\n",
        "\n",
        "  test_step(model=model,\n",
        "            data_loader=test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            accuracy_fn=accuracy_fn,\n",
        "            device=device)\n",
        "\n",
        "train_time_end_time = timer()\n",
        "total_train_time = print_train_time(start=train_time_start_time,\n",
        "                                    end=train_time_end_time,\n",
        "                                    device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "55c87a7c540b4055b4e987ac366f8692",
            "165e4a67f47040108bd7b510bfd539e1",
            "b96cdf3d15ac4516bffdee3f23fd6f54",
            "2aba8dfe4d834cc4b5081830ea2043d5",
            "9e183da2685f4b4080b997c3509581fc",
            "852afc9cf4b04fdebcdac4fc4b39ee39",
            "f40180d4ce584815815751e1efe78fc2",
            "ab8df6035446489ba143b5f07d18a3f3",
            "9532afe308dc46d2930f19537570c73a",
            "88e762f3d0e346199db7c8d6c3755ed5",
            "3aa76435fa9548ac8663dd25efdcfbcc"
          ]
        },
        "id": "4H1sjo4qGVPk",
        "outputId": "643249ed-becd-4314-f97c-1a86e9a40c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55c87a7c540b4055b4e987ac366f8692"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 \n",
            "-----------\n",
            "Train Loss: tensor(0.6041, device='cuda:0', grad_fn=<DivBackward0>) | Train Accuracy: tensor(0.7841, device='cuda:0')\n",
            "Test Loss: tensor(0.4019, device='cuda:0') | Test Accuracy: tensor(0.8582, device='cuda:0')\n",
            "Epoch: 1 \n",
            "-----------\n",
            "Train Loss: tensor(0.3530, device='cuda:0', grad_fn=<DivBackward0>) | Train Accuracy: tensor(0.8740, device='cuda:0')\n",
            "Test Loss: tensor(0.3866, device='cuda:0') | Test Accuracy: tensor(0.8605, device='cuda:0')\n",
            "Epoch: 2 \n",
            "-----------\n",
            "Train Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>) | Train Accuracy: tensor(0.8861, device='cuda:0')\n",
            "Test Loss: tensor(0.3441, device='cuda:0') | Test Accuracy: tensor(0.8787, device='cuda:0')\n",
            "Train time on cuda: 41.647 seconds\n"
          ]
        }
      ]
    }
  ]
}